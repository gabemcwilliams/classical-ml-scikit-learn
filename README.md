# Classical Machine Learning with Scikit-learn

This repository contains various classical machine learning workflows implemented using `scikit-learn`. It covers tasks
such as clustering, dimensionality reduction, regression, and more. Each notebook demonstrates practical examples using
real-world datasets and common machine learning techniques.

## Notebooks

### 1. **DBSCAN Clustering Example**

- **Description**: This notebook demonstrates the use of the DBSCAN (Density-Based Spatial Clustering of Applications
  with Noise) algorithm to identify clusters in data, including handling outliers.
- **Key Topics**:
    - DBSCAN algorithm and tuning epsilon
    - Visualizing clusters with scatter plots
    - Outlier detection

### 2. **K-Means Clustering**

- **Description**: This notebook covers the K-Means algorithm for clustering, including using different values of `k` to
  find optimal cluster numbers.
- **Key Topics**:
    - K-Means clustering
    - Elbow method to find optimal number of clusters
    - Visualizing clusters

### 3. **PCA (Principal Component Analysis) for Dimensionality Reduction**

- **Description**: A tutorial on PCA for reducing the dimensionality of datasets while retaining the most important
  features.
- **Key Topics**:
    - Data preprocessing and scaling
    - Applying PCA for dimensionality reduction
    - Visualizing transformed data in lower dimensions

### 4. **Random Forest Regression**

- **Description**: This notebook demonstrates the use of Random Forest Regression to predict continuous values (e.g.,
  predicting sales based on advertising data).
- **Key Topics**:
    - Train/validation/split of data
    - Feature scaling
    - Model training and evaluation metrics (MAE, RMSE)
    - Saving and loading models with `joblib`

### 5. **Hierarchical Clustering with Dendrogram**

- **Description**: Implements hierarchical clustering techniques using the agglomerative clustering algorithm and
  visualizing the results with dendrograms.
- **Key Topics**:
    - Agglomerative hierarchical clustering (AHC)
    - Dendrogram visualization
    - Distance thresholding for flexible clustering

### 6. **Linear Regression for Predicting Sales**

- **Description**: A basic implementation of linear regression to predict a target variable (sales) from multiple
  features (advertising spend).
- **Key Topics**:
    - Train/validation split
    - Linear regression model
    - Performance evaluation (R2, MAE, MSE)
      =======
- **Description**: This notebook demonstrates the use of the DBSCAN (Density-Based Spatial Clustering of Applications
  with Noise) algorithm to identify clusters in data, including handling outliers.
- **Key Topics**:
    - DBSCAN algorithm and tuning epsilon
    - Visualizing clusters with scatter plots
    - Outlier detection

### 2. **K-Means Clustering**

- **Description**: This notebook covers the K-Means algorithm for clustering, including using different values of `k` to
  find optimal cluster numbers.
- **Key Topics**:
    - K-Means clustering
    - Elbow method to find optimal number of clusters
    - Visualizing clusters

### 3. **PCA (Principal Component Analysis) for Dimensionality Reduction**

- **Description**: A tutorial on PCA for reducing the dimensionality of datasets while retaining the most important
  features.
- **Key Topics**:
    - Data preprocessing and scaling
    - Applying PCA for dimensionality reduction
    - Visualizing transformed data in lower dimensions

### 4. **Random Forest Regression**

- **Description**: This notebook demonstrates the use of Random Forest Regression to predict continuous values (e.g.,
  predicting sales based on advertising data).
- **Key Topics**:
    - Train/validation/split of data
    - Feature scaling
    - Model training and evaluation metrics (MAE, RMSE)
    - Saving and loading models with `joblib`

### 5. **Hierarchical Clustering with Dendrogram**

- **Description**: Implements hierarchical clustering techniques using the agglomerative clustering algorithm and
  visualizing the results with dendrograms.
- **Key Topics**:
    - Agglomerative hierarchical clustering (AHC)
    - Dendrogram visualization
    - Distance thresholding for flexible clustering

### 6. **Linear Regression for Predicting Sales**

- **Description**: A basic implementation of linear regression to predict a target variable (sales) from multiple
  features (advertising spend).
- **Key Topics**:
    - Train/validation split
    - Linear regression model
    - Performance evaluation (R2, MAE, MSE)

## Key Libraries

- `scikit-learn`: The main library used for building and evaluating machine learning models.
- `numpy`: Numerical computing and data manipulation.
- `matplotlib` and `seaborn`: Visualization tools for plotting graphs and distributions.
- `pandas`: Data manipulation and analysis.
- `joblib`: Used to save and load machine learning models.

## Learning Resources

- [Python for Machine Learning & Data Science Masterclass – Jose Portilla (Udemy)](https://www.udemy.com/course/python-for-machine-learning-data-science-masterclass)
- [Data Analysis in Python with pandas – Data School (YouTube)](https://www.youtube.com/playlist?list=PL5-da3qGB5ICCsgW1MxlZ0Hq8LL5U3u9y)
- [Machine Learning Tutorials – Rob Mulla (YouTube)](https://www.youtube.com/playlist?list=PL7RwtdVQXQ8o6CYe1Teo7FzkrQQoT0c9i)
